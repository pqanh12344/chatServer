# Build stage
FROM node:18 AS build

WORKDIR /app
COPY package.json package-lock.json* ./
RUN npm install
COPY . .
RUN npm run build

# Serve stage
FROM nginx:alpine

# Copy build ra nginx html folder
COPY --from=build /app/dist /usr/share/nginx/html

EXPOSE 8868

CMD ["nginx", "-g", "daemon off;"]



version: "3.9"

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: my-backend
    ports:
      - "9078:9078"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9078/api/hello"]
      interval: 10s
      timeout: 5s
      retries: 3

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: my-frontend
    ports:
      - "8868:80"   # nginx serve FE -> map ra port 8868
    restart: unless-stopped
    depends_on:
      backend:
        condition: service_healthy






import json
from llama_index.core import PropertyGraphIndex, TextNode, StorageContext, SimpleDirectoryStore
from llama_index.graph_stores.simple import SimplePropertyGraphStore

# ƒê·ªçc file JSON
json_file_path = "data.json"
with open(json_file_path, 'r', encoding='utf-8') as file:
    json_data = json.load(file)

# Kh·ªüi t·∫°o SimplePropertyGraphStore
graph_store = SimplePropertyGraphStore()

# T·∫°o nodes v√† relationships
nodes = []
relationships = []

for item in json_data:
    # T·∫°o node cho Property
    property_node = TextNode(
        text=f"{item['name']}: {item['value']}",
        metadata={
            "id": item["id"],
            "name": item["name"],
            "value": item["value"],
            "category": item["category"],
            "entity_type": "Property"
        }
    )
    nodes.append(property_node)

    # T·∫°o node cho Category
    category_node = TextNode(
        text=item["category"],
        metadata={
            "category": item["category"],
            "entity_type": "Category"
        }
    )
    nodes.append(category_node)

    # T·∫°o m·ªëi quan h·ªá
    relationships.append({
        "source_node_id": property_node.node_id,
        "target_node_id": category_node.node_id,
        "relationship_type": "BELONGS_TO_CATEGORY"
    })

# T·∫°o PropertyGraphIndex
index = PropertyGraphIndex(
    nodes=nodes,
    property_graph_store=graph_store,
    relationships=relationships
)

# L∆∞u index
storage_context = StorageContext.from_defaults(
    persist_dir="./property_graph_db",
    graph_store=graph_store
)
index.storage_context.persist(persist_dir="./property_graph_db")
print("ƒê√£ l∆∞u Property Graph v√†o ./property_graph_db!")

# Truy v·∫•n
query_engine = index.as_query_engine()
response = query_engine.query("T√¨m t·∫•t c·∫£ c√°c Property thu·ªôc category 'cat1'")
print("K·∫øt qu·∫£ truy v·∫•n:", response) c√≥ 









import json
from typing import Dict, Any, Optional
from llama_index.core import PropertyGraphIndex
from llama_index.core.graph_stores import SimplePropertyGraphStore
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core.schema import TextNode, Relation
from uuid import uuid4

class TextNodePropertyGraphBuilder:
    def __init__(self,
                 llm_model: str = "gpt-3.5-turbo",
                 embed_model: str = "text-embedding-3-small"):
        """Initialize PropertyGraphBuilder with LLM and embedding model"""
        self.llm = OpenAI(model=llm_model, temperature=0.0)
        self.embed_model = OpenAIEmbedding(model_name=embed_model)
        self.graph_store = SimplePropertyGraphStore()
        self.index = PropertyGraphIndex(
            nodes=[],
            llm=self.llm,
            embed_model=self.embed_model,
            property_graph_store=self.graph_store,
            embed_kg_nodes=True
        )

    def create_node(self, label: str, attributes: Dict[str, Any]) -> TextNode:
        """Create a TextNode with given label and attributes"""
        if 'id' not in attributes:
            raise ValueError("Node attributes must include 'id'")
        
        # Generate unique node_id
        node_id = str(uuid4())
        
        # Create TextNode with metadata
        metadata = attributes.copy()
        metadata['label'] = label
        
        node = TextNode(
            id_=node_id,
            text=f"{label}: {attributes.get('name', attributes['id'])}",
            metadata=metadata
        )
        
        # Insert node into graph store
        self.graph_store.upsert_nodes([node])
        self.index.insert(node)
        return node

    def create_relationship(self, source_label: str, source_id: str, 
                          target_label: str, target_id: str, 
                          rel_type: str, attributes: Optional[Dict[str, Any]] = None) -> Relation:
        """Create a relationship between two TextNodes with optional attributes"""
        # Find source and target nodes
        source_nodes = self.graph_store.get(properties={"id": source_id, "label": source_label})
        target_nodes = self.graph_store.get(properties={"id": target_id, "label": target_label})
        
        if not source_nodes:
            raise ValueError(f"Source node {source_label}:{source_id} does not exist")
        if not target_nodes:
            raise ValueError(f"Target node {target_label}:{target_id} does not exist")
        
        source_node = source_nodes[0]
        target_node = target_nodes[0]
        
        # Create relation
        relation = Relation(
            label=rel_type,
            source_id=source_node.id_,
            target_id=target_node.id_,
            properties=attributes if attributes else {}
        )
        
        # Insert relation into graph store
        self.graph_store.upsert_relations([relation])
        return relation

    def create_node_from_json(self, json_str: str) -> TextNode:
        """Create a TextNode from JSON string"""
        try:
            data = json.loads(json_str)
            label = data.get('label')
            attributes = data.get('attributes', {})
            if not label or not attributes:
                raise ValueError("JSON must contain 'label' and 'attributes'")
            return self.create_node(label, attributes)
        except json.JSONDecodeError:
            raise ValueError("Invalid JSON string")

    def create_relationship_from_json(self, json_str: str) -> Relation:
        """Create a relationship from JSON string"""
        try:
            data = json.loads(json_str)
            source_label = data.get('source_label')
            source_id = data.get('source_id')
            target_label = data.get('target_label')
            target_id = data.get('target_id')
            rel_type = data.get('rel_type')
            attributes = data.get('attributes', {})
            if not all([source_label, source_id, target_label, target_id, rel_type]):
                raise ValueError("JSON must contain 'source_label', 'source_id', 'target_label', 'target_id', and 'rel_type'")
            return self.create_relationship(source_label, source_id, target_label, target_id, rel_type, attributes)
        except json.JSONDecodeError:
            raise ValueError("Invalid JSON string")

    def get_all_nodes(self) -> list:
        """Return all nodes in the graph store"""
        return self.graph_store.get(properties={})

    def get_all_relationships(self) -> list:
        """Return all relationships in the graph store"""
        return self.graph_store.get_relations()

# Example usage
def main():
    # Initialize builder
    builder = TextNodePropertyGraphBuilder()

    try:
        # Example 1: Create a node directly
        person_attrs = {
            "id": "P001",
            "name": "John Doe",
            "age": 30
        }
        person = builder.create_node("PERSON", person_attrs)
        print(f"Created person node: {person}")

        # Example 2: Create a node from JSON
        company_json = '''
        {
            "label": "ORGANIZATION",
            "attributes": {
                "id": "C001",
                "name": "Tech Corp",
                "industry": "Technology"
            }
        }
        '''
        company = builder.create_node_from_json(company_json)
        print(f"Created company node: {company}")

        # Example 3: Create a relationship from JSON
        relationship_json = '''
        {
            "source_label": "PERSON",
            "source_id": "P001",
            "target_label": "ORGANIZATION",
            "target_id": "C001",
            "rel_type": "WORKS_FOR",
            "attributes": {
                "role": "Developer",
                "start_date": "2023-10-01"
            }
        }
        '''
        relationship = builder.create_relationship_from_json(relationship_json)
        print(f"Created relationship: {relationship}")

        # Print all nodes and relationships
        print("\nAll nodes:")
        for node in builder.get_all_nodes():
            print(f"{node.id_}: {node.metadata}")
        print("\nAll relationships:", builder.get_all_relationships())

    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    main()











import pandas as pd

def convert_csv_to_excel(csv_file_path, excel_file_path):
    # Read CSV file
    df = pd.read_csv(csv_file_path)
    
    # Convert to Excel
    df.to_excel(excel_file_path, index=False)
    print(f"Successfully converted {csv_file_path} to {excel_file_path}")

# Example usage
if __name__ == "__main__":
    csv_file = "input.csv"  # Replace with your CSV file path
    excel_file = "output.xlsx"  # Replace with desired Excel file path
    convert_csv_to_excel(csv_file, excel_file)



import streamlit as st
import time
import base64
from PIL import Image
import io
import os
import pandas as pd

# Thi·∫øt l·∫≠p c·∫•u h√¨nh trang
st.set_page_config(page_title="HAN", layout="wide", page_icon="üöñ")

# T√πy ch·ªânh CSS ƒë·ªÉ giao di·ªán gi·ªëng Grok v·ªõi n·ªÅn tr·∫Øng, tin nh·∫Øn kh√¥ng khung, m√†u ch·ªØ ƒëen, v√† xu·ªëng d√≤ng
st.markdown("""
    <style>
    .stApp {
        background-color: #ffffff;
        color: #000000;
        font-family: 'Arial', sans-serif;
    }
    .stChatMessage {
        border-radius: 10px;
        padding: 10px;
        margin: 5px 0;
        background-color: transparent; /* Kh√¥ng c√≥ m√†u n·ªÅn */
    }
    .user-message {
        background-color: transparent; /* H√≤a v·ªõi n·ªÅn tr·∫Øng */
        text-align: right;
        color: #000000; /* M√†u ƒëen */
        border: none; /* Kh√¥ng c√≥ khung */
        max-width: 80%; /* Gi·ªõi h·∫°n */
        word-wrap: break-word; /* T·ª± ƒë·ªông xu·ªëng d√≤ng */
        margin-left: auto; /* ƒê·∫©y sang ph·∫£i */
    }
    .assistant-message {
        background-color: transparent; /* H√≤a v·ªõi n·ªÅn tr·∫Øng */
        text-align: left;
        color: #000000; /* M√†u ƒëen */
        border: none; /* Kh√¥ng khung */
        max-width: 80%; /* Gi·ªõi h·∫°n */
        word-wrap: break-word; /* T·ª± ƒë·ªông xu·ªëng d√≤ng */
        margin-right: auto; /* ƒê·∫©y sang tr√°i */
    }
    .feedback-button {
        font-size: 12px;
        padding: 2px 8px;
        margin-left: 10px;
    }
    .stTextInput > div > div > input {
        background-color: #f0f0f0;
        color: #000000;
        border: 1px solid #cccccc;
        border-radius: 20px;
        padding: 10px;
    }
    .stButton > button {
        background-color: #1da1f2;
        color: #ffffff;
        border-radius: 20px;
        border: none;
        padding: 8px 16px;
    }
    .stButton > button:hover {
        background-color: #0d8bdc;
    }
    .sidebar .sidebar-content {
        background-color: #f8f8f8;
    }
    </style>
""", unsafe_allow_html=True)

# H√†m l∆∞u n·ªôi dung v√†o file CSV
def save_to_csv(user_message, bot_message, feedback, rating):
    data = {
        "UserMessage": [user_message],
        "BotMessage": [bot_message],
        "Feedback": [feedback],
        "Rating": [rating]
    }
    df = pd.DataFrame(data)
    file_exists = os.path.exists('chat_log.csv')
    df.to_csv('chat_log.csv', mode='a', header=not file_exists, index=False, encoding='utf-8')

# Kh·ªüi t·∫°o tr·∫°ng th√°i phi√™n
if "messages" not in st.session_state:
    st.session_state.messages = []
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = ""
if "selected_message_index" not in st.session_state:
    st.session_state.selected_message_index = None
if "last_user_message" not in st.session_state:
    st.session_state.last_user_message = ""
if "last_bot_message" not in st.session_state:
    st.session_state.last_bot_message = ""

# T·∫°o file CSV n·∫øu ch∆∞a t·ªìn t·∫°i
if not os.path.exists('chat_log.csv'):
    pd.DataFrame(columns=["UserMessage", "BotMessage", "Feedback", "Rating"]).to_csv('chat_log.csv', index=False, encoding='utf-8')

# Sidebar
with st.sidebar:
    st.header("HAN")
    if st.button("Clear Chat"):
        st.session_state.messages = []
        st.session_state.image_prompt = ""
        st.session_state.selected_message_index = None
        st.session_state.last_user_message = ""
        st.session_state.last_bot_message = ""

# Ti√™u ƒë·ªÅ ch√≠nh
st.markdown("<h1 style='text-align: center; color: #1da1f2;'>HAN</h1>", unsafe_allow_html=True)

# Khu v·ª±c tr√≤ chuy·ªán
chat_container = st.container()
with chat_container:
    for index, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            role_class = "user-message" if message["role"] == "user" else "assistant-message"
            if message["role"] == "assistant":
                # Hi·ªÉn th·ªã tin nh·∫Øn bot v·ªõi m·ªôt n√∫t ph·∫£n h·ªìi
                col1, col2 = st.columns([8, 1])
                with col1:
                    st.markdown(f"<div class='{role_class}'>{message['content']}</div>", unsafe_allow_html=True)
                with col2:
                    if st.button("üìù", key=f"feedback_{index}", help="Ph·∫£n h·ªìi c√¢u tr·∫£ l·ªùi", type="secondary"):
                        st.session_state.selected_message_index = index if st.session_state.selected_message_index != index else None
                # Hi·ªÉn th·ªã form ph·∫£n h·ªìi ngay d∆∞·ªõi tin nh·∫Øn n·∫øu ƒë∆∞·ª£c ch·ªçn
                if st.session_state.selected_message_index == index:
                    with st.container():
                        st.write(f"Ph·∫£n h·ªìi cho: {message['content'][:50]}...")
                        feedback = st.text_area("Nh·∫≠p ph·∫£n h·ªìi c·ªßa b·∫°n:", key=f"feedback_text_{index}")
                        rating = st.slider("ƒê√°nh gi√° (1-5):", 1, 5, 3, key=f"feedback_rating_{index}")
                        if st.button("G·ª≠i ph·∫£n h·ªìi", key=f"submit_feedback_{index}"):
                            # L∆∞u c·∫£ tin nh·∫Øn ng∆∞·ªùi d√πng, bot, v√† ph·∫£n h·ªìi v√†o CSV
                            save_to_csv(
                                user_message=st.session_state.last_user_message,
                                bot_message=message['content'],
                                feedback=feedback,
                                rating=rating
                            )
                            st.success("Ph·∫£n h·ªìi ƒë√£ ƒë∆∞·ª£c g·ª≠i! C·∫£m ∆°n b·∫°n!")
                            st.session_state.selected_message_index = None
            else:
                st.markdown(f"<div class='{role_class}'>{message['content']}</div>", unsafe_allow_html=True)
            if "image" in message:
                st.image(message["image"], caption="Generated by Grok", width=300)

# √î nh·∫≠p li·ªáu
prompt = st.chat_input("Ask me anything...")

# X·ª≠ l√Ω tin nh·∫Øn ng∆∞·ªùi d√πng
if prompt:
    # L∆∞u tin nh·∫Øn ng∆∞·ªùi d√πng v√†o tr·∫°ng th√°i
    st.session_state.last_user_message = prompt
    # Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng
    st.session_state.messages.append({"role": "user", "content": prompt})
    with chat_container:
        with st.chat_message("user"):
            st.markdown(f"<div class='user-message'>{prompt}</div>", unsafe_allow_html=True)
    
    # Gi·∫£ l·∫≠p ph·∫£n h·ªìi t·ª´ chatbot
    with chat_container:
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            response_text = f"T√¥i kh√¥ng bi·∫øt c√¢u h·ªèi n√†y {prompt}"
            for chunk in response_text.split():
                full_response += chunk + " "
                time.sleep(0.05)
                message_placeholder.markdown(f"<div class='assistant-message'>{full_response}‚ñå</div>", unsafe_allow_html=True)
            # Hi·ªÉn th·ªã ph·∫£n h·ªìi ho√†n ch·ªânh v·ªõi m·ªôt n√∫t ph·∫£n h·ªìi
            col1, col2 = st.columns([8, 1])
            with col1:
                message_placeholder.markdown(f"<div class='assistant-message'>{full_response}</div>", unsafe_allow_html=True)
            with col2:
                new_index = len(st.session_state.messages)
                if st.button("üìù", key=f"feedback_{new_index}", help="Ph·∫£n h·ªìi c√¢u tr·∫£ l·ªùi", type="secondary"):
                    st.session_state.selected_message_index = new_index if st.session_state.selected_message_index != index else None
            # Hi·ªÉn th·ªã form ph·∫£n h·ªìi ngay d∆∞·ªõi tin nh·∫Øn n·∫øu ƒë∆∞·ª£c ch·ªçn
            if st.session_state.selected_message_index == new_index:
                with st.container():
                    st.write(f"Ph·∫£n h·ªìi cho: {full_response[:50]}...")
                    feedback = st.text_area("Nh·∫≠p ph·∫£n h·ªìi c·ªßa b·∫°n:", key=f"feedback_text_{new_index}")
                    rating = st.slider("ƒê√°nh gi√° (1-5):", 1, 5, 3, key=f"feedback_rating_{new_index}")
                    if st.button("G·ª≠i ph·∫£n h·ªìi", key=f"submit_feedback_{new_index}"):
                        # L∆∞u c·∫£ tin nh·∫Øn ng∆∞·ªùi d√πng, bot, v√† ph·∫£n h·ªìi v√†o CSV
                        save_to_csv(
                            user_message=st.session_state.last_user_message,
                            bot_message=full_response,
                            feedback=feedback,
                            rating=rating
                        )
                        st.success("Ph·∫£n h·ªìi ƒë√£ ƒë∆∞·ª£c g·ª≠i! C·∫£m ∆°n b·∫°n!")
                        st.session_state.selected_message_index = None
    
    # L∆∞u tin nh·∫Øn bot v√†o tr·∫°ng th√°i
    st.session_state.last_bot_message = full_response
    # L∆∞u ph·∫£n h·ªìi
    st.session_state.messages.append({"role": "assistant", "content": full_response})







import streamlit as st
import time
import base64
from PIL import Image
import io

# Thi·∫øt l·∫≠p c·∫•u h√¨nh trang
st.set_page_config(page_title="Grok-like Chatbot", layout="wide", page_icon="üöÄ")

# T√πy ch·ªânh CSS ƒë·ªÉ giao di·ªán gi·ªëng Grok
st.markdown("""
    <style>
    .stApp {
        background-color: #0e1117;
        color: #ffffff;
        font-family: 'Arial', sans-serif;
    }
    .stChatMessage {
        border-radius: 10px;
        padding: 10px;
        margin: 5px 0;
    }
    .user-message {
        background-color: #1c2526;
        text-align: right;
    }
    .assistant-message {
        background-color: #2a2f3a;
        text-align: left;
    }
    .stTextInput > div > div > input {
        background-color: #1c2526;
        color: #ffffff;
        border: 1px solid #4a4a4a;
        border-radius: 20px;
        padding: 10px;
    }
    .stButton > button {
        background-color: #1da1f2;
        color: #ffffff;
        border-radius: 20px;
        border: none;
        padding: 8px 16px;
    }
    .stButton > button:hover {
        background-color: #0d8bdc;
    }
    .sidebar .sidebar-content {
        background-color: #161b22;
    }
    </style>
""", unsafe_allow_html=True)

# Kh·ªüi t·∫°o tr·∫°ng th√°i phi√™n
if "messages" not in st.session_state:
    st.session_state.messages = []
if "image_prompt" not in st.session_state:
    st.session_state.image_prompt = ""

# Sidebar
with st.sidebar:
    st.image("https://x.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FxAI-logo-dark.9e2e2a22.png&w=256&q=75", width=150)
    st.header("Grok-like AI Assistant")
    st.write("Powered by xAI-inspired design")
    if st.button("New Chat"):
        st.session_state.messages = []
        st.session_state.image_prompt = ""

# Ti√™u ƒë·ªÅ ch√≠nh
st.markdown("<h1 style='text-align: center; color: #1da1f2;'>Grok AI Assistant üöÄ</h1>", unsafe_allow_html=True)

# Khu v·ª±c tr√≤ chuy·ªán
chat_container = st.container()
with chat_container:
    for message in st.session_state.messages:
        role_class = "user-message" if message["role"] == "user" else "assistant-message"
        with st.chat_message(message["role"]):
            st.markdown(f"<div class='{role_class}'>{message['content']}</div>", unsafe_allow_html=True)
            if "image" in message:
                st.image(message["image"], caption="Generated by Grok", width=300)

# √î nh·∫≠p li·ªáu
col1, col2 = st.columns([8, 1])
with col1:
    prompt = st.chat_input("Ask me anything...")
with col2:
    generate_image = st.button("üé® Create Image")

# X·ª≠ l√Ω tin nh·∫Øn ng∆∞·ªùi d√πng
if prompt:
    # Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng
    st.session_state.messages.append({"role": "user", "content": prompt})
    with chat_container:
        with st.chat_message("user"):
            st.markdown(f"<div class='user-message'>{prompt}</div>", unsafe_allow_html=True)
    
    # Gi·∫£ l·∫≠p ph·∫£n h·ªìi t·ª´ chatbot
    with chat_container:
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            response_text = f"Here's my witty response to your query: *{prompt}*. I'm Grok, so expect some humor! üòé Let's say I'm processing this with my 200,000 GPU-powered brain... Done! What's next?"
            for chunk in response_text.split():
                full_response += chunk + " "
                time.sleep(0.05)
                message_placeholder.markdown(f"<div class='assistant-message'>{full_response}‚ñå</div>", unsafe_allow_html=True)
            message_placeholder.markdown(f"<div class='assistant-message'>{full_response}</div>", unsafe_allow_html=True)
    
    # L∆∞u ph·∫£n h·ªìi
    st.session_state.messages.append({"role": "assistant", "content": full_response})

# X·ª≠ l√Ω t·∫°o ·∫£nh
if generate_image and prompt:
    st.session_state.image_prompt = prompt
    with chat_container:
        with st.chat_message("assistant"):
            st.markdown("<div class='assistant-message'>Generating image based on your prompt... Hold tight! üñºÔ∏è</div>", unsafe_allow_html=True)
            
            # Gi·∫£ l·∫≠p t·∫°o ·∫£nh (thay th·∫ø b·∫±ng API th·ª±c t·∫ø n·∫øu c√≥)
            # ·ªû ƒë√¢y s·ª≠ d·ª•ng m·ªôt ·∫£nh m·∫´u
            img = Image.new('RGB', (300, 300), color = 'darkblue')
            d = io.BytesIO()
            img.save(d, format="PNG")
            img_bytes = d.getvalue()
            
            st.image(img_bytes, caption="Generated by Grok", width=300)
            st.markdown("<div class='assistant-message'>Here's your image! Want me to tweak it? üòÑ</div>", unsafe_allow_html=True)
    
    # L∆∞u tin nh·∫Øn v·ªõi ·∫£nh
    st.session_state.messages.append({
        "role": "assistant",
        "content": f"Generated image for: {prompt}",
        "image": img_bytes
    })




t√¥ihttps://nodejs.org/fr

npx create-react-app chatbot_frontend


cd chatbot_frontend
npm install axios

https://www.youtube.com/watch?v=u2NluvotA80

import React, { useState, useEffect, useRef } from 'react';
import axios from 'axios';
import './App.css';

function App() {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  const messageContainerRef = useRef(null);

  // L·∫•y l·ªãch s·ª≠ tr√≤ chuy·ªán khi t·∫£i trang
  useEffect(() => {
    const fetchMessages = async () => {
      try {
        const response = await axios.get('http://localhost:8000/api/messages/');
        setMessages(response.data);
      } catch (error) {
        console.error('L·ªói khi l·∫•y tin nh·∫Øn:', error);
      }
    };
    fetchMessages();
  }, []);

  // G·ª≠i tin nh·∫Øn
  const sendMessage = async () => {
    if (input.trim() === '') return;

    const userMessage = { sender: 'user', text: input };
    setMessages(prevMessages => [...prevMessages, userMessage]);

    try {
      const response = await axios.post('http://localhost:8000/api/chat/', { message: input });
      const botMessage = { sender: 'bot', text: response.data.response };
      setMessages(prevMessages => [...prevMessages, botMessage]);
    } catch (error) {
      console.error('L·ªói khi g·ª≠i tin nh·∫Øn:', error);
    }
    setInput('');
  };

  // Cu·ªôn xu·ªëng d∆∞·ªõi c√πng c·ªßa danh s√°ch tin nh·∫Øn
  useEffect(() => {
    if (messageContainerRef.current) {
      messageContainerRef.current.scrollTop = messageContainerRef.current.scrollHeight;
    }
  }, [messages]);

  return (
    <div className="chat-container">
      <div className="input-container">
        <input
          type="text"
          value={input}
          onChange={e => setInput(e.target.value)}
          onKeyPress={e => e.key === 'Enter' && sendMessage()}
          placeholder="H·ªèi b·∫•t k·ª≥ ƒëi·ªÅu g√¨..."
        />
        <button onClick={sendMessage}>G·ª≠i</button>
      </div>
      <div className="message-container" ref={messageContainerRef}>
        {messages.map((message, index) => (
          <div key={index} className={`message ${message.sender}`}>
            {message.text}
          </div>
        ))}
      </div>
    </div>
  );
}

export default App;



.chat-container {
  position: relative;
  width: 100vw;
  height: 100vh;
}

.input-container {
  position: absolute;
  top: 20%;
  left: 50%;
  transform: translate(-50%, -50%);
  display: flex;
  width: 80%;
  max-width: 600px;
}

.input-container input {
  flex: 1;
  padding: 10px;
  border: 1px solid #ddd;
  border-radius: 5px 0 0 5px;
}

.input-container button {
  padding: 10px;
  border: none;
  background-color: #007BFF;
  color: white;
  border-radius: 0 5px 5px 0;
}

.message-container {
  position: absolute;
  bottom: 0;
  left: 0;
  right: 0;
  height: 400px; /* C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh */
  overflow-y: auto;
  padding: 10px;
  background-color: #f9f9f9;
  border-top: 1px solid #ddd;
}

.message {
  margin: 5px 0;
  padding: 10px;
  border-radius: 10px;
  max-width: 80%;
}

.message.user {
  background-color: #DCF8C6; /* M√†u xanh nh·∫°t cho ng∆∞·ªùi d√πng */
  margin-left: auto;
}

.message.bot {
  background-color: #F0F0F0; /* M√†u x√°m nh·∫°t cho bot */
  margin-right: auto;
}



python -m venv myenv

pip install django djangorestframework django-cors-headers
django-admin startproject chatbot_backend
cd chatbot_backend

pip install Django
python manage.py startapp chat


Trong file chatbot_backend/settings.py, th√™m c√°c ·ª©ng d·ª•ng v√†o INSTALLED_APPS:


INSTALLED_APPS = [
    ...
    'rest_framework',
    'corsheaders',
    'chat',
]


Th√™m middleware v√† c·∫•u h√¨nh CORS:


MIDDLEWARE = [
    ...
    'corsheaders.middleware.CorsMiddleware',
    ...
]

CORS_ALLOW_ALL_ORIGINS = True



chat/models.py

from django.db import models

class Message(models.Model):
    SENDER_CHOICES = [
        ('user', 'User'),
        ('bot', 'Bot'),
    ]
    sender = models.CharField(max_length=4, choices=SENDER_CHOICES)
    text = models.TextField()
    timestamp = models.DateTimeField(auto_now_add=True)

    def __str__(self):
        return f"{self.sender}: {self.text[:20]}"




pip install djangorestframework
pip install django-cors-headers


python manage.py makemigrations
python manage.py migrate




Trong chat/serializers.py:


from rest_framework import serializers
from .models import Message

class MessageSerializer(serializers.ModelSerializer):
    class Meta:
        model = Message
        fields = ['id', 'sender', 'text', 'timestamp']



Trong chat/views.py


from rest_framework import generics
from rest_framework.views import APIView
from rest_framework.response import Response
from .models import Message
from .serializers import MessageSerializer

class MessageList(generics.ListAPIView):
    queryset = Message.objects.all().order_by('timestamp')
    serializer_class = MessageSerializer

class ChatView(APIView):
    def post(self, request):
        user_message_text = request.data.get('message')
        if not user_message_text:
            return Response({'error': 'Tin nh·∫Øn kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng'}, status=400)

        # L∆∞u tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng
        user_message = Message.objects.create(sender='user', text=user_message_text)

        # T·∫°o ph·∫£n h·ªìi t·ª´ bot
        bot_response_text = self.get_bot_response(user_message_text)
        Message.objects.create(sender='bot', text=bot_response_text)

        return Response({'response': bot_response_text})

    def get_bot_response(self, user_message):
        # Logic ph·∫£n h·ªìi ƒë∆°n gi·∫£n d·ª±a tr√™n t·ª´ kh√≥a
        keywords = {
            'hello': 'Xin ch√†o b·∫°n!',
            'how are you': 'M√¨nh kh·ªèe, c·∫£m ∆°n b·∫°n!',
            'bye': 'T·∫°m bi·ªát!',
        }
        for key in keywords:
            if key in user_message.lower():
                return keywords[key]
        return 'M√¨nh kh√¥ng bi·∫øt tr·∫£ l·ªùi th·∫ø n√†o.'




chat/urls.py:


from django.urls import path
from .views import MessageList, ChatView

urlpatterns = [
    path('messages/', MessageList.as_view(), name='message-list'),
    path('chat/', ChatView.as_view(), name='chat'),
]



Trong chatbot_backend/urls.py:


from django.contrib import admin
from django.urls import path, include

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/', include('chat.urls')),
]

python manage.py runserver
Backend s·∫Ω ch·∫°y t·∫°i http://localhost:8000



import torch
import torch.nn as nn
from transformers import AutoModel, AutoTokenizer
from torch.utils.data import DataLoader, Dataset
import torch.nn.functional as F

# H√†m m·∫•t m√°t InfoNCE
class InfoNCELoss(nn.Module):
    def __init__(self, temperature=0.07):
        super(InfoNCELoss, self).__init__()
        self.temperature = temperature

    def forward(self, features_1, features_2, labels):
        # Chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng
        features_1 = F.normalize(features_1, p=2, dim=1)
        features_2 = F.normalize(features_2, p=2, dim=1)
        # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng
        similarity_matrix = torch.matmul(features_1, features_2.T) / self.temperature
        # T·∫°o nh√£n cho c·∫∑p positive (c√πng ch·ªâ s·ªë)
        batch_size = features_1.shape[0]
        labels = torch.arange(batch_size, device=features_1.device)
        # T√≠nh loss
        loss = F.cross_entropy(similarity_matrix, labels)
        return loss

# Dataset t√πy ch·ªânh
class TextPairDataset(Dataset):
    def __init__(self, texts_1, texts_2, labels):
        self.texts_1 = texts_1  # Danh s√°ch vƒÉn b·∫£n 1
        self.texts_2 = texts_2  # Danh s√°ch vƒÉn b·∫£n 2 (positive/negative pairs)
        self.labels = labels    # Nh√£n: 1 cho positive, 0 cho negative
        self.tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

    def __len__(self):
        return len(self.texts_1)

    def __getitem__(self, idx):
        text_1 = self.texts_1[idx]
        text_2 = self.texts_2[idx]
        label = self.labels[idx]
        encoding_1 = self.tokenizer(text_1, return_tensors="pt", padding="max_length", truncation=True, max_length=128)
        encoding_2 = self.tokenizer(text_2, return_tensors="pt", padding="max_length", truncation=True, max_length=128)
        return {
            "input_ids_1": encoding_1["input_ids"].squeeze(),
            "attention_mask_1": encoding_1["attention_mask"].squeeze(),
            "input_ids_2": encoding_2["input_ids"].squeeze(),
            "attention_mask_2": encoding_2["attention_mask"].squeeze(),
            "label": label
        }

# M√¥ h√¨nh
class TextContrastiveModel(nn.Module):
    def __init__(self, model_name="bert-base-uncased"):
        super(TextContrastiveModel, self).__init__()
        self.bert = AutoModel.from_pretrained(model_name)
        self.pooling = nn.AdaptiveAvgPool1d(1)  # Mean pooling

    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids, attention_mask=attention_mask)
        # L·∫•y hidden states c·ªßa token [CLS] ho·∫∑c mean pooling
        embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling
        return embeddings

# D·ªØ li·ªáu m·∫´u
texts_1 = ["I love this movie!", "This film is great!", "I hate this movie."]
texts_2 = ["This movie is amazing!", "I enjoyed the film.", "This film is terrible."]
labels = [1, 1, 0]  # 1: positive pair, 0: negative pair

# T·∫°o dataset v√† dataloader
dataset = TextPairDataset(texts_1, texts_2, labels)
dataloader = DataLoader(dataset, batch_size=2, shuffle=True)

# Kh·ªüi t·∫°o m√¥ h√¨nh v√† h√†m m·∫•t m√°t
model = TextContrastiveModel()
criterion = InfoNCELoss(temperature=0.07)
optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)

# Hu·∫•n luy·ªán
model.train()
for epoch in range(3):
    for batch in dataloader:
        optimizer.zero_grad()
        input_ids_1 = batch["input_ids_1"]
        attention_mask_1 = batch["attention_mask_1"]
        input_ids_2 = batch["input_ids_2"]
        attention_mask_2 = batch["attention_mask_2"]
        labels = batch["label"].float()

        # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
        features_1 = model(input_ids_1, attention_mask_1)
        features_2 = model(input_ids_2, attention_mask_2)

        # T√≠nh loss
        loss = criterion(features_1, features_2, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch {epoch+1}, Loss: {loss.item()}")

# Ph√¢n lo·∫°i (tinh ch·ªânh)
class TextClassifier(nn.Module):
    def __init__(self, pretrained_model):
        super(TextClassifier, self).__init__()
        self.bert = pretrained_model
        self.fc = nn.Linear(768, 2)  # Gi·∫£ s·ª≠ ph√¢n lo·∫°i nh·ªã ph√¢n (positive/negative)

    def forward(self, input_ids, attention_mask):
        embeddings = self.bert(input_ids, attention_mask)
        logits = self.fc(embeddings)
        return logits

# Tinh ch·ªânh cho ph√¢n lo·∫°i
classifier = TextClassifier(model)
# Ti·∫øp t·ª•c hu·∫•n luy·ªán v·ªõi cross-entropy loss cho b√†i to√°n ph√¢n lo·∫°i
