https://github.com/lucidrains/conformer/blob/master/conformer/conformer.py
https://github.com/jreremy/conformer
https://github.com/sooftware/conformer/tree/main/conformer
https://github.com/xiabingquan/Automatic-Speech-Recognition-from-Scratch/tree/main





import moviepy.editor as mp
import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np

# Step 1: Extract audio from the video
def extract_audio_from_video(video_path, audio_path):
    video = mp.VideoFileClip(video_path)
    audio = video.audio
    audio.write_audiofile(audio_path)

# Step 2: Generate and plot Mel spectrogram
def plot_mel_spectrogram(audio_path):
    # Load the audio file
    y, sr = librosa.load(audio_path, sr=None)  # sr=None to preserve the original sample rate
    
    # Generate a Mel spectrogram
    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)
    
    # Convert to decibel scale (log scale)
    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)
    
    # Plot the Mel spectrogram
    plt.figure(figsize=(10, 6))
    librosa.display.specshow(mel_spectrogram_db, x_axis='time', y_axis='mel', sr=sr)
    plt.colorbar(format='%+2.0f dB')
    plt.title('Mel Spectrogram')
    plt.show()

# Paths to your video and audio files
video_path = "your_video.mp4"
audio_path = "extracted_audio.wav"

# Extract the audio from the video
extract_audio_from_video(video_path, audio_path)

# Generate and display the Mel spectrogram
plot_mel_spectrogram(audio_path)








import moviepy.editor as mp
import librosa
import librosa.display
import matplotlib.pyplot as plt

# Step 1: Extract audio from the video
def extract_audio_from_video(video_path, audio_path):
    video = mp.VideoFileClip(video_path)
    audio = video.audio
    audio.write_audiofile(audio_path)

# Step 2: Generate and plot MFCCs
def plot_mfcc(audio_path):
    # Load the audio file
    y, sr = librosa.load(audio_path, sr=None)  # sr=None preserves the original sample rate
    
    # Compute MFCCs (using 13 coefficients, which is standard)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    
    # Plot MFCCs
    plt.figure(figsize=(10, 6))
    librosa.display.specshow(mfccs, x_axis='time', sr=sr)
    plt.colorbar(format='%+2.0f dB')
    plt.title('MFCCs')
    plt.show()

# Paths to your video and audio files
video_path = "your_video.mp4"
audio_path = "extracted_audio.wav"

# Extract the audio from the video
extract_audio_from_video(video_path, audio_path)

# Generate and display the MFCCs
plot_mfcc(audio_path)




https://nodejs.org/fr

npx create-react-app chatbot_frontend


cd chatbot_frontend
npm install axios

import React, { useState, useEffect, useRef } from 'react';
import axios from 'axios';
import './App.css';

function App() {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  const messageContainerRef = useRef(null);

  // Lấy lịch sử trò chuyện khi tải trang
  useEffect(() => {
    const fetchMessages = async () => {
      try {
        const response = await axios.get('http://localhost:8000/api/messages/');
        setMessages(response.data);
      } catch (error) {
        console.error('Lỗi khi lấy tin nhắn:', error);
      }
    };
    fetchMessages();
  }, []);

  // Gửi tin nhắn
  const sendMessage = async () => {
    if (input.trim() === '') return;

    const userMessage = { sender: 'user', text: input };
    setMessages(prevMessages => [...prevMessages, userMessage]);

    try {
      const response = await axios.post('http://localhost:8000/api/chat/', { message: input });
      const botMessage = { sender: 'bot', text: response.data.response };
      setMessages(prevMessages => [...prevMessages, botMessage]);
    } catch (error) {
      console.error('Lỗi khi gửi tin nhắn:', error);
    }
    setInput('');
  };

  // Cuộn xuống dưới cùng của danh sách tin nhắn
  useEffect(() => {
    if (messageContainerRef.current) {
      messageContainerRef.current.scrollTop = messageContainerRef.current.scrollHeight;
    }
  }, [messages]);

  return (
    <div className="chat-container">
      <div className="input-container">
        <input
          type="text"
          value={input}
          onChange={e => setInput(e.target.value)}
          onKeyPress={e => e.key === 'Enter' && sendMessage()}
          placeholder="Hỏi bất kỳ điều gì..."
        />
        <button onClick={sendMessage}>Gửi</button>
      </div>
      <div className="message-container" ref={messageContainerRef}>
        {messages.map((message, index) => (
          <div key={index} className={`message ${message.sender}`}>
            {message.text}
          </div>
        ))}
      </div>
    </div>
  );
}

export default App;



.chat-container {
  position: relative;
  width: 100vw;
  height: 100vh;
}

.input-container {
  position: absolute;
  top: 20%;
  left: 50%;
  transform: translate(-50%, -50%);
  display: flex;
  width: 80%;
  max-width: 600px;
}

.input-container input {
  flex: 1;
  padding: 10px;
  border: 1px solid #ddd;
  border-radius: 5px 0 0 5px;
}

.input-container button {
  padding: 10px;
  border: none;
  background-color: #007BFF;
  color: white;
  border-radius: 0 5px 5px 0;
}

.message-container {
  position: absolute;
  bottom: 0;
  left: 0;
  right: 0;
  height: 400px; /* Có thể điều chỉnh */
  overflow-y: auto;
  padding: 10px;
  background-color: #f9f9f9;
  border-top: 1px solid #ddd;
}

.message {
  margin: 5px 0;
  padding: 10px;
  border-radius: 10px;
  max-width: 80%;
}

.message.user {
  background-color: #DCF8C6; /* Màu xanh nhạt cho người dùng */
  margin-left: auto;
}

.message.bot {
  background-color: #F0F0F0; /* Màu xám nhạt cho bot */
  margin-right: auto;
}



python -m venv myenv

pip install django djangorestframework django-cors-headers
django-admin startproject chatbot_backend
cd chatbot_backend

pip install Django
python manage.py startapp chat


Trong file chatbot_backend/settings.py, thêm các ứng dụng vào INSTALLED_APPS:


INSTALLED_APPS = [
    ...
    'rest_framework',
    'corsheaders',
    'chat',
]


Thêm middleware và cấu hình CORS:


MIDDLEWARE = [
    ...
    'corsheaders.middleware.CorsMiddleware',
    ...
]

CORS_ALLOW_ALL_ORIGINS = True



chat/models.py

from django.db import models

class Message(models.Model):
    SENDER_CHOICES = [
        ('user', 'User'),
        ('bot', 'Bot'),
    ]
    sender = models.CharField(max_length=4, choices=SENDER_CHOICES)
    text = models.TextField()
    timestamp = models.DateTimeField(auto_now_add=True)

    def __str__(self):
        return f"{self.sender}: {self.text[:20]}"




pip install djangorestframework
pip install django-cors-headers


python manage.py makemigrations
python manage.py migrate




Trong chat/serializers.py:


from rest_framework import serializers
from .models import Message

class MessageSerializer(serializers.ModelSerializer):
    class Meta:
        model = Message
        fields = ['id', 'sender', 'text', 'timestamp']



Trong chat/views.py


from rest_framework import generics
from rest_framework.views import APIView
from rest_framework.response import Response
from .models import Message
from .serializers import MessageSerializer

class MessageList(generics.ListAPIView):
    queryset = Message.objects.all().order_by('timestamp')
    serializer_class = MessageSerializer

class ChatView(APIView):
    def post(self, request):
        user_message_text = request.data.get('message')
        if not user_message_text:
            return Response({'error': 'Tin nhắn không được để trống'}, status=400)

        # Lưu tin nhắn của người dùng
        user_message = Message.objects.create(sender='user', text=user_message_text)

        # Tạo phản hồi từ bot
        bot_response_text = self.get_bot_response(user_message_text)
        Message.objects.create(sender='bot', text=bot_response_text)

        return Response({'response': bot_response_text})

    def get_bot_response(self, user_message):
        # Logic phản hồi đơn giản dựa trên từ khóa
        keywords = {
            'hello': 'Xin chào bạn!',
            'how are you': 'Mình khỏe, cảm ơn bạn!',
            'bye': 'Tạm biệt!',
        }
        for key in keywords:
            if key in user_message.lower():
                return keywords[key]
        return 'Mình không biết trả lời thế nào.'




chat/urls.py:


from django.urls import path
from .views import MessageList, ChatView

urlpatterns = [
    path('messages/', MessageList.as_view(), name='message-list'),
    path('chat/', ChatView.as_view(), name='chat'),
]



Trong chatbot_backend/urls.py:


from django.contrib import admin
from django.urls import path, include

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/', include('chat.urls')),
]

python manage.py runserver
Backend sẽ chạy tại http://localhost:8000





import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

# Giả sử bạn đã có chunks và chunk_embeddings
# chunks = ["đoạn văn 1", "đoạn văn 2", ..., "đoạn văn 250000"]
# chunk_embeddings = np.random.randn(250000, 768).astype('float32')  # Ví dụ, thay bằng dữ liệu thực tế

# Đảm bảo chunk_embeddings là float32
chunk_embeddings = chunk_embeddings.astype('float32')

# Số chiều của vector embedding
d = chunk_embeddings.shape[1]

# Số lượng centroid
nlist = 500

# Tạo quantizer
quantizer = faiss.IndexFlatL2(d)

# Tạo index IVFFlat
index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)

# Huấn luyện index
print("Đang huấn luyện index...")
index.train(chunk_embeddings)
print("Huấn luyện hoàn tất.")

# Thêm vector vào index
print("Đang thêm vector vào index...")
index.add(chunk_embeddings)
print("Thêm vector hoàn tất.")

# Tùy chọn: Tăng nprobe để cải thiện độ chính xác
index.nprobe = 10

# Tùy chọn: Sử dụng GPU nếu có
if faiss.get_num_gpus() > 0:
    res = faiss.StandardGpuResources()
    index = faiss.index_cpu_to_gpu(res, 0, index)
    print("Đã chuyển index sang GPU.")
else:
    print("Không có GPU, sử dụng CPU.")

# Khởi tạo mô hình Sentence Transformer
model = SentenceTransformer('all-MiniLM-L6-v2')

# Câu query
query_text = "your query text here"  # Thay bằng câu truy vấn của bạn
query_embedding = model.encode([query_text]).astype('float32')

# Số lượng kết quả muốn trả về
k = 10

# Thực hiện tìm kiếm
print("Đang thực hiện tìm kiếm...")
distances, indices = index.search(query_embedding, k)
print("Tìm kiếm hoàn tất.")

# Xử lý kết quả
print("\nKết quả tìm kiếm:")
for i in range(k):
    print(f"Kết quả {i+1}:")
    print(f"Đoạn văn: {chunks[indices[0][i]]}")
    print(f"Khoảng cách: {distances[0][i]}")
    print("---")



import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

# Giả sử bạn đã có dữ liệu
# chunks = ["đoạn văn 1", "đoạn văn 2", ..., "đoạn văn 250000"]
# chunk_embeddings = np.random.randn(250000, 768).astype('float32')  # Thay bằng dữ liệu thực tế

# Đảm bảo chunk_embeddings là float32
chunk_embeddings = chunk_embeddings.astype('float32')

# Số chiều của vector embedding
d = chunk_embeddings.shape[1]

# Số lượng centroid
nlist = 500

# Tạo quantizer
quantizer = faiss.IndexFlatL2(d)

# Tạo index IVFFlat
index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)

# Huấn luyện index
print("Đang huấn luyện index...")
index.train(chunk_embeddings)
print("Huấn luyện hoàn tất.")

# Định nghĩa batch_size
batch_size = 10000  # Có thể điều chỉnh

# Tính số lượng batch
num_batches = (len(chunk_embeddings) + batch_size - 1) // batch_size

# Thêm vector theo batch
print("Đang thêm vector vào index theo batch...")
for i in range(num_batches):
    start_idx = i * batch_size
    end_idx = min((i + 1) * batch_size, len(chunk_embeddings))
    batch = chunk_embeddings[start_idx:end_idx]
    index.add(batch)
    print(f"Đã thêm batch {i+1}/{num_batches}")
print("Thêm vector hoàn tất.")

# Khởi tạo mô hình Sentence Transformer
model = SentenceTransformer('all-MiniLM-L6-v2')

# Câu query
query_text = "your query text here"  # Thay bằng câu truy vấn của bạn
query_embedding = model.encode([query_text]).astype('float32')

# Số lượng kết quả muốn trả về
k = 10

# Thực hiện tìm kiếm
print("Đang thực hiện tìm kiếm...")
distances, indices = index.search(query_embedding, k)
print("Tìm kiếm hoàn tất.")

# Xử lý kết quả
print("\nKết quả tìm kiếm:")
for i in range(k):
    print(f"Kết quả {i+1}:")
    print(f"Đoạn văn: {chunks[indices[0][i]]}")
    print(f"Khoảng cách: {distances[0][i]}")
    print("---")





import numpy as np
from qdrant_client import QdrantClient
from qdrant_client.http import models
from sentence_transformers import SentenceTransformer

# Khởi tạo Qdrant Client
client = QdrantClient("localhost", port=6333)

# Đặt tên collection
collection_name = "my_collection"

# Kiểm tra và tạo collection nếu chưa tồn tại
if not client.collection_exists(collection_name):
    client.create_collection(
        collection_name=collection_name,
        vectors_config=models.VectorParams(
            size=768,  # Kích thước vector embedding
            distance=models.Distance.COSINE  # Khoảng cách Cosine
        ),
    )

# Giả sử bạn đã có dữ liệu
# chunks = ["đoạn văn 1", "đoạn văn 2", ..., "đoạn văn 250000"]  # 250,000 đoạn văn
# chunk_embeddings = np.random.rand(250000, 768)  # Ví dụ, thay bằng dữ liệu thực tế của bạn

# Tạo danh sách ID
ids = list(range(len(chunks)))

# Chuyển chunk_embeddings sang list
vectors = chunk_embeddings.tolist()

# Upload dữ liệu theo batch
batch_size = 1000
for i in range(0, len(ids), batch_size):
    batch_ids = ids[i:i + batch_size]
    batch_vectors = vectors[i:i + batch_size]
    client.upload_collection(
        collection_name=collection_name,
        vectors=batch_vectors,
        ids=batch_ids,
    )
    print(f"Uploaded batch {i // batch_size + 1}/{len(ids) // batch_size + 1}")

# Khởi tạo mô hình Sentence Transformer
model = SentenceTransformer('all-MiniLM-L6-v2')

# Tạo query
query_text = "your query text here"  # Thay bằng câu truy vấn của bạn
query_embedding = model.encode(query_text).tolist()

# Thực hiện tìm kiếm
search_result = client.search(
    collection_name=collection_name,
    query_vector=query_embedding,
    limit=10,
)

# Xử lý kết quả
print("\nKết quả tìm kiếm:")
for hit in search_result:
    print(f"ID: {hit.id}, Score: {hit.score}")
    print(f"Đoạn văn: {chunks[hit.id]}")
    print("---")
